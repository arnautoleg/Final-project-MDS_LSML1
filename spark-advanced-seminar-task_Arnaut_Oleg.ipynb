{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CGHGHkqE4rJw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tqdm.notebook as tqdm\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3duPlU1fjxPz"
   },
   "source": [
    "# Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jovyan\n",
      " * Starting OpenBSD Secure Shell server sshd\n",
      "start-stop-daemon: unable to set gid to 0 (Operation not permitted)\n",
      "   ...fail!\n",
      " * sshd is running\n",
      "Starting namenodes on [localhost]\n",
      "localhost: Warning: Permanently added 'localhost' (ED25519) to the list of known hosts.\n",
      "localhost: namenode is running as process 166.  Stop it first and ensure /tmp/hadoop-jovyan-namenode.pid file is empty before retry.\n",
      "Starting datanodes\n",
      "localhost: Warning: Permanently added 'localhost' (ED25519) to the list of known hosts.\n",
      "localhost: datanode is running as process 272.  Stop it first and ensure /tmp/hadoop-jovyan-datanode.pid file is empty before retry.\n",
      "Starting secondary namenodes [c5cc60baf499]\n",
      "c5cc60baf499: Warning: Permanently added 'c5cc60baf499' (ED25519) to the list of known hosts.\n",
      "c5cc60baf499: secondarynamenode is running as process 502.  Stop it first and ensure /tmp/hadoop-jovyan-secondarynamenode.pid file is empty before retry.\n",
      "Starting resourcemanager\n",
      "resourcemanager is running as process 767.  Stop it first and ensure /tmp/hadoop-jovyan-resourcemanager.pid file is empty before retry.\n",
      "Starting nodemanagers\n",
      "localhost: Warning: Permanently added 'localhost' (ED25519) to the list of known hosts.\n",
      "localhost: nodemanager is running as process 885.  Stop it first and ensure /tmp/hadoop-jovyan-nodemanager.pid file is empty before retry.\n",
      "WARNING: Use of this script to start the MR JobHistory daemon is deprecated.\n",
      "WARNING: Attempting to execute replacement \"mapred --daemon start\" instead.\n",
      "272 org.apache.hadoop.hdfs.server.datanode.DataNode\n",
      "2325 org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer\n",
      "885 org.apache.hadoop.yarn.server.nodemanager.NodeManager\n",
      "502 org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode\n",
      "166 org.apache.hadoop.hdfs.server.namenode.NameNode\n",
      "2361 sun.tools.jps.Jps -lm\n",
      "767 org.apache.hadoop.yarn.server.resourcemanager.ResourceManager\n",
      "Configured Capacity: 269490393088 (250.98 GB)\n",
      "Present Capacity: 229294202880 (213.55 GB)\n",
      "DFS Remaining: 224596107264 (209.17 GB)\n",
      "DFS Used: 4698095616 (4.38 GB)\n",
      "DFS Used%: 2.05%\n",
      "Replicated Blocks:\n",
      "\tUnder replicated blocks: 0\n",
      "\tBlocks with corrupt replicas: 0\n",
      "\tMissing blocks: 0\n",
      "\tMissing blocks (with replication factor 1): 0\n",
      "\tLow redundancy blocks with highest priority to recover: 0\n",
      "\tPending deletion blocks: 0\n",
      "Erasure Coded Block Groups: \n",
      "\tLow redundancy block groups: 0\n",
      "\tBlock groups with corrupt internal blocks: 0\n",
      "\tMissing block groups: 0\n",
      "\tLow redundancy blocks with highest priority to recover: 0\n",
      "\tPending deletion blocks: 0\n",
      "\n",
      "-------------------------------------------------\n",
      "Live datanodes (1):\n",
      "\n",
      "Name: 127.0.0.1:9866 (localhost)\n",
      "Hostname: c5cc60baf499\n",
      "Decommission Status : Normal\n",
      "Configured Capacity: 269490393088 (250.98 GB)\n",
      "DFS Used: 4698095616 (4.38 GB)\n",
      "Non DFS Used: 26435518464 (24.62 GB)\n",
      "DFS Remaining: 224596107264 (209.17 GB)\n",
      "DFS Used%: 1.74%\n",
      "DFS Remaining%: 83.34%\n",
      "Configured Cache Capacity: 0 (0 B)\n",
      "Cache Used: 0 (0 B)\n",
      "Cache Remaining: 0 (0 B)\n",
      "Cache Used%: 100.00%\n",
      "Cache Remaining%: 0.00%\n",
      "Xceivers: 0\n",
      "Last contact: Tue Apr 11 07:54:47 UTC 2023\n",
      "Last Block Report: Tue Apr 11 07:53:39 UTC 2023\n",
      "Num of Blocks: 354\n",
      "\n",
      "\n",
      "chmod: changing permissions of '/home/jovyan/jupyter.log': Operation not permitted\n",
      "chmod: changing permissions of '/home/jovyan/nginx.log': Operation not permitted\n",
      "chmod: changing permissions of '/home/jovyan/error.log': Operation not permitted\n",
      "chmod: changing permissions of '/home/jovyan/access.log': Operation not permitted\n"
     ]
    }
   ],
   "source": [
    "! /home/jovyan/start-hadoop.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "u566smRWkDOS",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2023-04-11 07:54:55,670 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "# connect, context, session\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName='jupyter')\n",
    "\n",
    "from pyspark.sql import SparkSession, Row\n",
    "se = SparkSession(sc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCrxvDnx47f2"
   },
   "source": [
    "## HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-tZacCcy49Lv",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem                Size   Used  Available  Use%\n",
      "hdfs://localhost:9000  251.0 G  4.7 G    208.6 G    2%\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1m8mBXzZ4-kB",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\n",
      "drwxr-xr-x   - jovyan supergroup          0 2023-04-11 03:22 /actors.jsonl\n",
      "drwxrwx---   - root   supergroup          0 2023-04-10 18:19 /tmp\n",
      "drwxr-xr-x   - jovyan supergroup          0 2023-04-10 18:19 /user\n",
      "drwxr-xr-x   - jovyan supergroup          0 2023-04-11 03:21 /wiki\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Q1OO-vOyY6L"
   },
   "source": [
    "## Broadcast and accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RjypNMTVyYOp",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[5] at RDD at PythonRDD.scala:53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:=====================================================>   (30 + 2) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 2)]\n",
      "errors: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "bc = sc.broadcast({\"this\": 0, \"is\": 1, \"text\": 2})\n",
    "errors = sc.accumulator(0)\n",
    "\n",
    "def mapper(x):\n",
    "    global errors\n",
    "    for w in x.split():\n",
    "        if w in bc.value:\n",
    "            yield (bc.value[w], 1)\n",
    "        else:\n",
    "            errors += 1\n",
    "\n",
    "rdd = (\n",
    "    sc\n",
    "   .parallelize([\"this is text\", \"text too\"])\n",
    "   .flatMap(mapper)\n",
    "   .reduceByKey(lambda a, b: a + b)\n",
    ")\n",
    "print(rdd)\n",
    "print(rdd.collect())\n",
    "print(\"errors:\", errors.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHR7Vzn_jxlF"
   },
   "source": [
    "## DataFrame API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDbdsczvj_i8"
   },
   "source": [
    "RDD is much better and useful than plain MapReduce, but Spark can do even more!\n",
    "Spark DataFrame is table structure over RDDs and can be treated as pandas on steroids.\n",
    "\n",
    "It allows us to perform structured queries and benefit from it. One way is to perform SQL-styled queries (will discuss on next lesson) and another is DataFrame API.\n",
    "\n",
    "Documentation: https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "EpYvw_HymmTQ",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('a', 2), ('b', 3), ('b', 4)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([(\"a\", 1), (\"a\", 2), (\"b\", 3), (\"b\", 4)])\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "i4mxAmRemmb2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: string (nullable = true)\n",
      " |-- _2: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| _1| _2|\n",
      "+---+---+\n",
      "|  a|  1|\n",
      "|  a|  2|\n",
      "|  b|  3|\n",
      "|  b|  4|\n",
      "+---+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = se.createDataFrame(rdd)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FGJOiQS_2G_-",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- col_one: string (nullable = true)\n",
      " |-- col_two: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|col_one|col_two|\n",
      "+-------+-------+\n",
      "|      a|      1|\n",
      "|      a|      2|\n",
      "|      b|      3|\n",
      "|      b|      4|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "df = se.createDataFrame(\n",
    "    rdd.map(lambda x: Row(col_one=x[0], col_two=x[1]))\n",
    ")\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "u1RymT0N7n8z",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:==================================================>     (18 + 2) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|col_one|\n",
      "+-------+\n",
      "|      a|\n",
      "|      a|\n",
      "+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select(['col_one']).limit(2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "wwkvZly3774s",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a', 'b']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(['col_one']).distinct().rdd.map(lambda x: x.col_one).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docs: https://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#module-pyspark.sql.functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "D_QIAytR70kc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:====================================================>   (30 + 2) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|col_one|col_two|\n",
      "+-------+-------+\n",
      "|      a|      1|\n",
      "|      a|      2|\n",
      "+-------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "(\n",
    "  df.select(['col_one', 'col_two'])\n",
    "    .where(F.col('col_one') == 'a')\n",
    "    .limit(2)\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "rNp94hJnjHqW",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------------+\n",
      "|col_one|col_two|col_two_float|\n",
      "+-------+-------+-------------+\n",
      "|      a|      1|          1.0|\n",
      "|      a|      2|          2.0|\n",
      "|      b|      3|          3.0|\n",
      "|      b|      4|          4.0|\n",
      "+-------+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.select('*', df['col_two'].cast('float').alias('col_two_float'))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "fMgcNpPmjTUM",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|col_one|col_two_square|\n",
      "+-------+--------------+\n",
      "|      b|          16.0|\n",
      "|      b|           9.0|\n",
      "|      a|           4.0|\n",
      "|      a|           1.0|\n",
      "+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "square_df = df.select('col_one', (df['col_two_float'] * df['col_two_float']).alias('col_two_square'))\n",
    "square_df.orderBy('col_two_square', ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6TO3OLMN7W51",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:======================================================> (31 + 1) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+\n",
      "|col_one|col_two_list|\n",
      "+-------+------------+\n",
      "|      b|      [4, 3]|\n",
      "|      a|      [1, 2]|\n",
      "+-------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "(\n",
    "    df\n",
    "      .groupby('col_one')\n",
    "      .agg(F.collect_list(\"col_two\").alias(\"col_two_list\"))\n",
    "      .select(['col_one', 'col_two_list'])\n",
    "      .limit(10)\n",
    "      .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "lc31NQ0x2Lv-"
   },
   "source": [
    "# convertable to Pandas\n",
    "pandas_df = df.toPandas()\n",
    "pandas_df\n",
    "\n",
    "# load from Pandas\n",
    "df = se.createDataFrame(pandas_df)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(col_one='a', col_two=1, col_two_float=1.0),\n",
       " Row(col_one='a', col_two=2, col_two_float=2.0),\n",
       " Row(col_one='b', col_two=3, col_two_float=3.0),\n",
       " Row(col_one='b', col_two=4, col_two_float=4.0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.toLocalIterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = se.createDataFrame(df.toLocalIterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- col_one: string (nullable = true)\n",
      " |-- col_two: long (nullable = true)\n",
      " |-- col_two_float: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------------+\n",
      "|col_one|col_two|col_two_float|\n",
      "+-------+-------+-------------+\n",
      "|      a|      1|          1.0|\n",
      "|      a|      2|          2.0|\n",
      "|      b|      3|          3.0|\n",
      "|      b|      4|          4.0|\n",
      "+-------+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "PYlbgkZI3QiH",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(col_one='a', col_two=1, col_two_float=1.0),\n",
       " Row(col_one='a', col_two=2, col_two_float=2.0),\n",
       " Row(col_one='b', col_two=3, col_two_float=3.0),\n",
       " Row(col_one='b', col_two=4, col_two_float=4.0)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# also can get RDD from DF\n",
    "df.rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qi3keNw6mteI"
   },
   "source": [
    "## Data formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Mt8434r9mvr2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We may want to operate with not just plain text, but something more complex\n",
    "# For example, Parquet - it can be useful for huge datasets for faster calcs\n",
    "#df.write.save(\"data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "zxDJLG6pmvwf"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#data = se.read.parquet(\"data.parquet\")\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mrdd\u001b[38;5;241m.\u001b[39mcollect()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "#data = se.read.parquet(\"data.parquet\")\n",
    "#data.rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1NJypwklF_Z"
   },
   "source": [
    "## Outbrain click prediction dataseet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twX4Yeez5Loj"
   },
   "source": [
    "https://www.kaggle.com/c/outbrain-click-prediction/data - you need to register here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Kaggle/kaggle-api\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# instruction where to get ~/.kaggle/kaggle.json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/jovyan/.kaggle/kaggle.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile ~/.kaggle/kaggle.json\n",
    "{\"username\":\"olegarnaut\", \"key\":\"b9a74d5ee3e1b8bf97b22d4b2d881f5e\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "j4FsSCqe5CvG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (1.24.3)\n",
      "Collecting urllib3\n",
      "  Using cached urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "Requirement already satisfied: kaggle==1.5.3 in /opt/conda/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kaggle==1.5.3) (4.65.0)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from kaggle==1.5.3) (2.8.2)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.10/site-packages (from kaggle==1.5.3) (1.16.0)\n",
      "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle==1.5.3) (8.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kaggle==1.5.3) (2.28.2)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from kaggle==1.5.3) (2022.12.7)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle==1.5.3) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle==1.5.3) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle==1.5.3) (3.4)\n",
      "Downloading page_views_sample.csv.zip to /home/jovyan/work\n",
      "100%|████████████████████████████████████████| 149M/149M [00:23<00:00, 4.92MB/s]\n",
      "100%|████████████████████████████████████████| 149M/149M [00:23<00:00, 6.65MB/s]\n",
      "Downloading events.csv.zip to /home/jovyan/work\n",
      "100%|████████████████████████████████████████| 478M/478M [01:28<00:00, 6.11MB/s]\n",
      "100%|████████████████████████████████████████| 478M/478M [01:28<00:00, 5.68MB/s]\n",
      "Downloading documents_topics.csv.zip to /home/jovyan/work\n",
      "100%|████████████████████████████████████████| 121M/121M [00:20<00:00, 6.31MB/s]\n",
      "100%|████████████████████████████████████████| 121M/121M [00:20<00:00, 6.06MB/s]\n",
      "Downloading documents_entities.csv.zip to /home/jovyan/work\n",
      "100%|████████████████████████████████████████| 126M/126M [00:21<00:00, 6.08MB/s]\n",
      "100%|████████████████████████████████████████| 126M/126M [00:21<00:00, 6.12MB/s]\n",
      "Downloading documents_meta.csv.zip to /home/jovyan/work\n",
      " 97%|████████████████████████████████████▋ | 15.0M/15.5M [00:02<00:00, 7.31MB/s]\n",
      "100%|██████████████████████████████████████| 15.5M/15.5M [00:02<00:00, 6.38MB/s]\n",
      "Downloading clicks_test.csv.zip to /home/jovyan/work\n",
      "100%|███████████████████████████████████████▊| 135M/135M [00:23<00:00, 6.19MB/s]\n",
      "100%|████████████████████████████████████████| 135M/135M [00:23<00:00, 6.05MB/s]\n",
      "Downloading clicks_train.csv.zip to /home/jovyan/work\n",
      "100%|████████████████████████████████████████| 390M/390M [01:08<00:00, 6.05MB/s]\n",
      "100%|████████████████████████████████████████| 390M/390M [01:08<00:00, 5.96MB/s]\n",
      "Downloading documents_categories.csv.zip to /home/jovyan/work\n",
      " 99%|█████████████████████████████████████▌| 32.0M/32.3M [00:05<00:00, 6.17MB/s]\n",
      "100%|██████████████████████████████████████| 32.3M/32.3M [00:05<00:00, 6.24MB/s]\n",
      "Downloading promoted_content.csv.zip to /home/jovyan/work\n",
      " 80%|██████████████████████████████▏       | 2.00M/2.52M [00:00<00:00, 3.93MB/s]\n",
      "100%|██████████████████████████████████████| 2.52M/2.52M [00:00<00:00, 4.11MB/s]\n"
     ]
    }
   ],
   "source": [
    "! pip install -U urllib3 kaggle==1.5.3\n",
    "! kaggle competitions download -c outbrain-click-prediction -f page_views_sample.csv.zip\n",
    "! kaggle competitions download -c outbrain-click-prediction -f events.csv.zip \n",
    "! kaggle competitions download -c outbrain-click-prediction -f documents_topics.csv.zip \n",
    "! kaggle competitions download -c outbrain-click-prediction -f documents_entities.csv.zip \n",
    "! kaggle competitions download -c outbrain-click-prediction -f documents_meta.csv.zip \n",
    "! kaggle competitions download -c outbrain-click-prediction -f clicks_test.csv.zip\n",
    "! kaggle competitions download -c outbrain-click-prediction -f clicks_train.csv.zip\n",
    "! kaggle competitions download -c outbrain-click-prediction -f documents_categories.csv.zip\n",
    "! kaggle competitions download -c outbrain-click-prediction -f promoted_content.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open *.zip, *.zip.zip or *.zip.ZIP.\n",
      "\n",
      "No zipfiles found.\n"
     ]
    }
   ],
   "source": [
    "! unzip '*.zip'\n",
    "! rm -rf *.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put: `page_views_sample.csv': File exists\n",
      "put: `documents_topics.csv': File exists\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -put page_views_sample.csv\n",
    "! hdfs dfs -put events.csv\n",
    "! hdfs dfs -put documents_topics.csv\n",
    "! hdfs dfs -put documents_entities.csv\n",
    "! hdfs dfs -put documents_meta.csv\n",
    "! hdfs dfs -put clicks_test.csv\n",
    "! hdfs dfs -put clicks_train.csv\n",
    "! hdfs dfs -put documents_categories.csv\n",
    "! hdfs dfs -put promoted_content.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "V5Qx5EkolI_0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+---------+--------+------------+--------------+\n",
      "|          uuid|document_id|timestamp|platform|geo_location|traffic_source|\n",
      "+--------------+-----------+---------+--------+------------+--------------+\n",
      "|1fd5f051fba643|        120| 31905835|       1|          RS|             2|\n",
      "|8557aa9004be3b|        120| 32053104|       1|       VN>44|             2|\n",
      "|c351b277a358f0|        120| 54013023|       1|       KR>12|             1|\n",
      "|8205775c5387f9|        120| 44196592|       1|       IN>16|             2|\n",
      "|9cb0ccd8458371|        120| 65817371|       1|   US>CA>807|             2|\n",
      "+--------------+-----------+---------+--------+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "df = se.read.csv(\"page_views_sample.csv\", header=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3orFyft25Tk_"
   },
   "source": [
    "### Data manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "lUkB7pVjmnAB"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53e8716574c44f495af0217204e9e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicks_test\n",
      "+----------+------+\n",
      "|display_id| ad_id|\n",
      "+----------+------+\n",
      "|  16874594| 66758|\n",
      "|  16874594|150083|\n",
      "|  16874594|162754|\n",
      "+----------+------+\n",
      "\n",
      "clicks_train\n",
      "+----------+------+-------+\n",
      "|display_id| ad_id|clicked|\n",
      "+----------+------+-------+\n",
      "|         1| 42337|      0|\n",
      "|         1|139684|      0|\n",
      "|         1|144739|      1|\n",
      "+----------+------+-------+\n",
      "\n",
      "documents_categories\n",
      "+-----------+-----------+----------------+\n",
      "|document_id|category_id|confidence_level|\n",
      "+-----------+-----------+----------------+\n",
      "|    1595802|       1611|            0.92|\n",
      "|    1595802|       1610|            0.07|\n",
      "|    1524246|       1807|            0.92|\n",
      "+-----------+-----------+----------------+\n",
      "\n",
      "documents_entities\n",
      "+-----------+--------------------+-----------------+\n",
      "|document_id|           entity_id| confidence_level|\n",
      "+-----------+--------------------+-----------------+\n",
      "|    1524246|f9eec25663db4cd83...|0.672865314504701|\n",
      "|    1524246|55ebcfbdaff1d6f60...|0.399113728441297|\n",
      "|    1524246|839907a972930b17b...|0.392095749652966|\n",
      "+-----------+--------------------+-----------------+\n",
      "\n",
      "documents_meta\n",
      "+-----------+---------+------------+-------------------+\n",
      "|document_id|source_id|publisher_id|       publish_time|\n",
      "+-----------+---------+------------+-------------------+\n",
      "|    1595802|        1|         603|2016-06-05 00:00:00|\n",
      "|    1524246|        1|         603|2016-05-26 11:00:00|\n",
      "|    1617787|        1|         603|2016-05-27 00:00:00|\n",
      "+-----------+---------+------------+-------------------+\n",
      "\n",
      "documents_topics\n",
      "+-----------+--------+------------------+\n",
      "|document_id|topic_id|  confidence_level|\n",
      "+-----------+--------+------------------+\n",
      "|    1595802|     140|0.0731131601068925|\n",
      "|    1595802|      16|0.0594164867373976|\n",
      "|    1595802|     143|0.0454207537554526|\n",
      "+-----------+--------+------------------+\n",
      "\n",
      "events\n",
      "+----------+--------------+-----------+---------+--------+------------+\n",
      "|display_id|          uuid|document_id|timestamp|platform|geo_location|\n",
      "+----------+--------------+-----------+---------+--------+------------+\n",
      "|         1|cb8c55702adb93|     379743|       61|       3|   US>SC>519|\n",
      "|         2|79a85fa78311b9|    1794259|       81|       2|   US>CA>807|\n",
      "|         3|822932ce3d8757|    1179111|      182|       2|   US>MI>505|\n",
      "+----------+--------------+-----------+---------+--------+------------+\n",
      "\n",
      "page_views_sample\n",
      "+--------------+-----------+---------+--------+------------+--------------+\n",
      "|          uuid|document_id|timestamp|platform|geo_location|traffic_source|\n",
      "+--------------+-----------+---------+--------+------------+--------------+\n",
      "|1fd5f051fba643|        120| 31905835|       1|          RS|             2|\n",
      "|8557aa9004be3b|        120| 32053104|       1|       VN>44|             2|\n",
      "|c351b277a358f0|        120| 54013023|       1|       KR>12|             1|\n",
      "+--------------+-----------+---------+--------+------------+--------------+\n",
      "\n",
      "promoted_content\n",
      "+-----+-----------+-----------+-------------+\n",
      "|ad_id|document_id|campaign_id|advertiser_id|\n",
      "+-----+-----------+-----------+-------------+\n",
      "|    1|       6614|          1|            7|\n",
      "|    2|     471467|          2|            7|\n",
      "|    3|       7692|          3|            7|\n",
      "+-----+-----------+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "tables = [\"clicks_test\", \"clicks_train\", \n",
    "          \"documents_categories\", \"documents_entities\", \"documents_meta\", \"documents_topics\", \n",
    "          \"events\", \"page_views_sample\", \"promoted_content\"]\n",
    "for name in tqdm.tqdm(tables):\n",
    "    df = se.read.csv(\"{}.csv\".format(name), header=True)\n",
    "    df.registerTempTable(name)\n",
    "    print(name)\n",
    "    df.limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "dyN3IF_LmnCZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[uuid: string, document_id: string, timestamp: string, platform: string, geo_location: string, traffic_source: string]\n"
     ]
    }
   ],
   "source": [
    "page_views = se.table(\"page_views_sample\")\n",
    "print(page_views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+---------+--------+------------+--------------+\n",
      "|          uuid|document_id|timestamp|platform|geo_location|traffic_source|\n",
      "+--------------+-----------+---------+--------+------------+--------------+\n",
      "|1fd5f051fba643|        120| 31905835|       1|          RS|             2|\n",
      "|8557aa9004be3b|        120| 32053104|       1|       VN>44|             2|\n",
      "|c351b277a358f0|        120| 54013023|       1|       KR>12|             1|\n",
      "|8205775c5387f9|        120| 44196592|       1|       IN>16|             2|\n",
      "|9cb0ccd8458371|        120| 65817371|       1|   US>CA>807|             2|\n",
      "|2aa611f32875c7|        120| 71495491|       1|       CA>ON|             2|\n",
      "|f55a6eaf2b34ab|        120| 73309199|       1|       BR>27|             2|\n",
      "|cc01b582c8cbff|        120| 50033577|       1|       CA>BC|             2|\n",
      "|6c802978b8dd4d|        120| 66590306|       1|       CA>ON|             2|\n",
      "|f4e423314303ff|        120| 48314254|       1|   US>LA>622|             1|\n",
      "|3937372ca2709b|        120| 24360074|       1|          NO|             2|\n",
      "|31f8d101c6a851|        120| 13847456|       1|       PH>D9|             2|\n",
      "|67606983fe1acf|        984| 82129416|       2|   US>OK>671|             2|\n",
      "|3f9d5b09ac4a0a|        984| 82583638|       2|          US|             2|\n",
      "|3dd8a359aa8699|        984| 59439284|       2|   US>MD>511|             2|\n",
      "|95e966c81b9316|        984|   983791|       3|   US>AL>698|             2|\n",
      "|483cf1feb3e47c|        984| 17944009|       2|   US>MI>505|             1|\n",
      "|f7baf0caf201ca|        984| 37096677|       2|       CA>AB|             2|\n",
      "|7a408fe90c02b3|        984| 30457643|       1|          PH|             1|\n",
      "|9ee2877617838a|        984| 86093121|       3|   US>MN>613|             2|\n",
      "+--------------+-----------+---------+--------+------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "page_views.select('*').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+---------+--------+------------+--------------+\n",
      "|          uuid|document_id|timestamp|platform|geo_location|traffic_source|\n",
      "+--------------+-----------+---------+--------+------------+--------------+\n",
      "|1fd5f051fba643|        120| 31905835|       1|          RS|             2|\n",
      "|8557aa9004be3b|        120| 32053104|       1|       VN>44|             2|\n",
      "|c351b277a358f0|        120| 54013023|       1|       KR>12|             1|\n",
      "|8205775c5387f9|        120| 44196592|       1|       IN>16|             2|\n",
      "|9cb0ccd8458371|        120| 65817371|       1|   US>CA>807|             2|\n",
      "|2aa611f32875c7|        120| 71495491|       1|       CA>ON|             2|\n",
      "|f55a6eaf2b34ab|        120| 73309199|       1|       BR>27|             2|\n",
      "|cc01b582c8cbff|        120| 50033577|       1|       CA>BC|             2|\n",
      "|6c802978b8dd4d|        120| 66590306|       1|       CA>ON|             2|\n",
      "|f4e423314303ff|        120| 48314254|       1|   US>LA>622|             1|\n",
      "|3937372ca2709b|        120| 24360074|       1|          NO|             2|\n",
      "|31f8d101c6a851|        120| 13847456|       1|       PH>D9|             2|\n",
      "|67606983fe1acf|        984| 82129416|       2|   US>OK>671|             2|\n",
      "|3f9d5b09ac4a0a|        984| 82583638|       2|          US|             2|\n",
      "|3dd8a359aa8699|        984| 59439284|       2|   US>MD>511|             2|\n",
      "|95e966c81b9316|        984|   983791|       3|   US>AL>698|             2|\n",
      "|483cf1feb3e47c|        984| 17944009|       2|   US>MI>505|             1|\n",
      "|f7baf0caf201ca|        984| 37096677|       2|       CA>AB|             2|\n",
      "|7a408fe90c02b3|        984| 30457643|       1|          PH|             1|\n",
      "|9ee2877617838a|        984| 86093121|       3|   US>MN>613|             2|\n",
      "+--------------+-----------+---------+--------+------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "page_views_sql = se.sql(\"SELECT * from page_views_sample\")\n",
    "page_views_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "3DWOaQBSmnJT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[document_id: string, topic_id: string, confidence_level: string]\n"
     ]
    }
   ],
   "source": [
    "documents_topics = se.table(\"documents_topics\")\n",
    "print(documents_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "mxLQczih7AhS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 132:===================================================>   (32 + 2) / 34]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|document_id|topic_id|\n",
      "+-----------+--------+\n",
      "|     999924|     184|\n",
      "|     999924|     184|\n",
      "|     999924|     223|\n",
      "|     999924|     223|\n",
      "|     999924|     223|\n",
      "|     999924|     223|\n",
      "|     999924|     184|\n",
      "|     999924|     223|\n",
      "|     999924|     184|\n",
      "|     999924|     223|\n",
      "|     999924|     184|\n",
      "|     999924|     223|\n",
      "|     999924|     184|\n",
      "|     999924|     184|\n",
      "|     999924|     223|\n",
      "|     999924|     184|\n",
      "|     999924|     184|\n",
      "|     999924|     184|\n",
      "|     999924|     223|\n",
      "|     999924|     184|\n",
      "+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import desc\n",
    "\n",
    "(\n",
    "    page_views\n",
    "      .join(documents_topics, page_views.document_id == documents_topics.document_id, 'outer')\n",
    "      .select(page_views.document_id, documents_topics.topic_id)\n",
    "      .sort(desc(\"document_id\"))\n",
    "      .limit(50)\n",
    "      .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 135:=====================================================> (33 + 1) / 34]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|document_id|              topics|\n",
      "+-----------+--------------------+\n",
      "|    1000015|          [183, 283]|\n",
      "|    1000067|[199, 183, 229, 1...|\n",
      "|    1000073|           [183, 35]|\n",
      "|    1000096|      [173, 254, 71]|\n",
      "|     100010|[16, 254, 192, 25...|\n",
      "|    1000113|      [184, 183, 35]|\n",
      "|    1000128|           [183, 35]|\n",
      "|    1000131|[183, 199, 235, 1...|\n",
      "|    1000146|      [183, 35, 202]|\n",
      "|    1000167|      [183, 35, 202]|\n",
      "+-----------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "  documents_topics\n",
    "    .groupby('document_id')\n",
    "    .agg(F.collect_list(\"topic_id\").alias(\"topics\"))\n",
    "    .limit(10)\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 141:===================================================>   (26 + 2) / 28]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|document_id|topics_cnt|\n",
      "+-----------+----------+\n",
      "|    1451809|         1|\n",
      "|    2256862|         1|\n",
      "|    1388193|         1|\n",
      "|    2284422|         1|\n",
      "|    1801253|         1|\n",
      "|    2114730|         1|\n",
      "|    1877485|         1|\n",
      "|    2885936|         1|\n",
      "|     196385|         1|\n",
      "|      79893|         1|\n",
      "+-----------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "  documents_topics\n",
    "    .groupby('document_id')\n",
    "    .agg(F.count(\"topic_id\").alias(\"topics_cnt\"))\n",
    "    .orderBy(\"topics_cnt\")\n",
    "    .limit(10)\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 148:===================================================>   (32 + 2) / 34]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|document_id|topics_cnt|\n",
      "+-----------+----------+\n",
      "|    2643193|         1|\n",
      "|    2637627|         1|\n",
      "|    1827717|         1|\n",
      "|    1775420|         1|\n",
      "|    2896006|         1|\n",
      "|    2977112|         1|\n",
      "|    2221038|         1|\n",
      "|    2784051|         1|\n",
      "|    2208732|         1|\n",
      "|    2030781|         1|\n",
      "+-----------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "  documents_topics\n",
    "    .groupby('document_id')\n",
    "    .agg(F.countDistinct(\"topic_id\").alias(\"topics_cnt\"))\n",
    "    .orderBy(\"topics_cnt\")\n",
    "    .limit(10)\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 150:===================================================>   (30 + 2) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|traffic_source|\n",
      "+--------------+\n",
      "|             3|\n",
      "|             1|\n",
      "|             2|\n",
      "+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "page_views.select(\"traffic_source\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[traffic_source#486], functions=[])\n",
      "   +- Exchange hashpartitioning(traffic_source#486, 200), ENSURE_REQUIREMENTS, [plan_id=987]\n",
      "      +- HashAggregate(keys=[traffic_source#486], functions=[])\n",
      "         +- FileScan csv [traffic_source#486] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://localhost:9000/user/jovyan/page_views_sample.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<traffic_source:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "page_views.select(\"traffic_source\").distinct().explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(document_id='1373067', topic_id='120', confidence_level='0.00800022845571354', row_number=0),\n",
       " Row(document_id='1772411', topic_id='224', confidence_level='0.00800066703451342', row_number=0),\n",
       " Row(document_id='16439', topic_id='126', confidence_level='0.0080008012801282', row_number=0),\n",
       " Row(document_id='1744048', topic_id='98', confidence_level='0.00800159041703942', row_number=0),\n",
       " Row(document_id='1721729', topic_id='100', confidence_level='0.00800006482315529', row_number=0),\n",
       " Row(document_id='1126279', topic_id='27', confidence_level='0.00800065149060317', row_number=0),\n",
       " Row(document_id='1367225', topic_id='140', confidence_level='0.00800012204207135', row_number=0),\n",
       " Row(document_id='1543668', topic_id='171', confidence_level='0.00800380736393708', row_number=0),\n",
       " Row(document_id='935225', topic_id='71', confidence_level='0.00800009549206651', row_number=0),\n",
       " Row(document_id='654417', topic_id='284', confidence_level='0.00800013440001791', row_number=0),\n",
       " Row(document_id='113635', topic_id='5', confidence_level='0.00800018262447156', row_number=0),\n",
       " Row(document_id='839275', topic_id='163', confidence_level='0.00800007565433593', row_number=0),\n",
       " Row(document_id='2281646', topic_id='75', confidence_level='0.00800059856285632', row_number=0),\n",
       " Row(document_id='583662', topic_id='61', confidence_level='0.00800047574960686', row_number=0),\n",
       " Row(document_id='2932259', topic_id='131', confidence_level='0.00800011749422134', row_number=0),\n",
       " Row(document_id='1060702', topic_id='35', confidence_level='0.00800002923513077', row_number=0),\n",
       " Row(document_id='825697', topic_id='223', confidence_level='0.00800005536785343', row_number=0),\n",
       " Row(document_id='147341', topic_id='183', confidence_level='0.00800056864897607', row_number=0),\n",
       " Row(document_id='1545601', topic_id='188', confidence_level='0.00800438957516853', row_number=0),\n",
       " Row(document_id='1713491', topic_id='110', confidence_level='0.00800004776978301', row_number=0),\n",
       " Row(document_id='1528667', topic_id='267', confidence_level='0.00800002816000525', row_number=0),\n",
       " Row(document_id='97253', topic_id='96', confidence_level='0.00800002709333477', row_number=0),\n",
       " Row(document_id='2705772', topic_id='43', confidence_level='0.00800011628122133', row_number=0),\n",
       " Row(document_id='2488273', topic_id='174', confidence_level='0.00800025676909156', row_number=0),\n",
       " Row(document_id='245374', topic_id='18', confidence_level='0.00800016426675426', row_number=0),\n",
       " Row(document_id='1618840', topic_id='22', confidence_level='0.00800032805621377', row_number=0),\n",
       " Row(document_id='970998', topic_id='166', confidence_level='0.00800047377786989', row_number=0),\n",
       " Row(document_id='1571366', topic_id='219', confidence_level='0.00800020583123362', row_number=0),\n",
       " Row(document_id='1922221', topic_id='274', confidence_level='0.00800227633723358', row_number=0),\n",
       " Row(document_id='1737168', topic_id='132', confidence_level='0.00800024842107568', row_number=0),\n",
       " Row(document_id='1869311', topic_id='17', confidence_level='0.00800041771724787', row_number=0),\n",
       " Row(document_id='2810973', topic_id='133', confidence_level='0.00800204134697929', row_number=0),\n",
       " Row(document_id='1795631', topic_id='251', confidence_level='0.00800840976261161', row_number=0),\n",
       " Row(document_id='870797', topic_id='234', confidence_level='0.00800000204081684', row_number=0),\n",
       " Row(document_id='1382424', topic_id='99', confidence_level='0.00800032192007726', row_number=0),\n",
       " Row(document_id='1378875', topic_id='34', confidence_level='0.00800002837333938', row_number=0),\n",
       " Row(document_id='1369135', topic_id='276', confidence_level='0.00800056074546351', row_number=0),\n",
       " Row(document_id='1450684', topic_id='187', confidence_level='0.00800008391306855', row_number=0),\n",
       " Row(document_id='40574', topic_id='47', confidence_level='0.00800036176007957', row_number=0),\n",
       " Row(document_id='76361', topic_id='8', confidence_level='0.00800035650487743', row_number=0),\n",
       " Row(document_id='1820377', topic_id='195', confidence_level='0.00800005376000286', row_number=0),\n",
       " Row(document_id='1771673', topic_id='107', confidence_level='0.00800083967475122', row_number=0),\n",
       " Row(document_id='1939630', topic_id='179', confidence_level='0.00800007203623664', row_number=0),\n",
       " Row(document_id='1210186', topic_id='160', confidence_level='0.00800055060004129', row_number=0),\n",
       " Row(document_id='857730', topic_id='202', confidence_level='0.00800000023668639', row_number=0),\n",
       " Row(document_id='268936', topic_id='221', confidence_level='0.00800042476198341', row_number=0),\n",
       " Row(document_id='1511542', topic_id='248', confidence_level='0.00800022223858919', row_number=0),\n",
       " Row(document_id='1500699', topic_id='203', confidence_level='0.00800034439649907', row_number=0),\n",
       " Row(document_id='489921', topic_id='31', confidence_level='0.0080008014972619', row_number=0),\n",
       " Row(document_id='2008655', topic_id='70', confidence_level='0.00800187440970282', row_number=0),\n",
       " Row(document_id='1457228', topic_id='258', confidence_level='0.00800022348257593', row_number=0),\n",
       " Row(document_id='107970', topic_id='87', confidence_level='0.00800030024941398', row_number=0),\n",
       " Row(document_id='297280', topic_id='287', confidence_level='0.00800007654822722', row_number=0),\n",
       " Row(document_id='464561', topic_id='168', confidence_level='0.00800001705882854', row_number=0),\n",
       " Row(document_id='803340', topic_id='206', confidence_level='0.00800026794670953', row_number=0),\n",
       " Row(document_id='25834', topic_id='29', confidence_level='0.00800011960079601', row_number=0),\n",
       " Row(document_id='1784643', topic_id='218', confidence_level='0.00800120664882591', row_number=0),\n",
       " Row(document_id='1569466', topic_id='11', confidence_level='0.00800006131022799', row_number=0),\n",
       " Row(document_id='1159159', topic_id='205', confidence_level='0.00800578470616592', row_number=0),\n",
       " Row(document_id='1778182', topic_id='101', confidence_level='0.00800099213923395', row_number=0),\n",
       " Row(document_id='2314403', topic_id='232', confidence_level='0.00800047837258846', row_number=0),\n",
       " Row(document_id='705829', topic_id='125', confidence_level='0.00800004807512413', row_number=0),\n",
       " Row(document_id='1399822', topic_id='184', confidence_level='0.00800085901318781', row_number=0),\n",
       " Row(document_id='911861', topic_id='3', confidence_level='0.008002472715809', row_number=0),\n",
       " Row(document_id='1573296', topic_id='30', confidence_level='0.00800008651687822', row_number=0),\n",
       " Row(document_id='325951', topic_id='112', confidence_level='0.00800007209638379', row_number=0),\n",
       " Row(document_id='1205392', topic_id='52', confidence_level='0.00800003350319164', row_number=0),\n",
       " Row(document_id='304916', topic_id='138', confidence_level='0.00800040000004986', row_number=0),\n",
       " Row(document_id='788930', topic_id='296', confidence_level='0.00800029921495886', row_number=0),\n",
       " Row(document_id='1260717', topic_id='7', confidence_level='0.00800043733347276', row_number=0),\n",
       " Row(document_id='2579981', topic_id='16', confidence_level='0.00800000296943338', row_number=0),\n",
       " Row(document_id='1053757', topic_id='42', confidence_level='0.00800010507773925', row_number=0),\n",
       " Row(document_id='1176840', topic_id='146', confidence_level='0.00800000064000004', row_number=0),\n",
       " Row(document_id='356260', topic_id='162', confidence_level='0.00800095791321005', row_number=0),\n",
       " Row(document_id='735672', topic_id='0', confidence_level='0.00800023470954348', row_number=0),\n",
       " Row(document_id='1535749', topic_id='154', confidence_level='0.00800017773302881', row_number=0),\n",
       " Row(document_id='792988', topic_id='139', confidence_level='0.00800024587159722', row_number=0),\n",
       " Row(document_id='906719', topic_id='298', confidence_level='0.00800137745468856', row_number=0),\n",
       " Row(document_id='1476523', topic_id='59', confidence_level='0.00800086698171831', row_number=0),\n",
       " Row(document_id='378282', topic_id='64', confidence_level='0.00800109043286055', row_number=0),\n",
       " Row(document_id='978451', topic_id='250', confidence_level='0.00800013986145446', row_number=0),\n",
       " Row(document_id='1390144', topic_id='85', confidence_level='0.00800047605123181', row_number=0),\n",
       " Row(document_id='1568732', topic_id='272', confidence_level='0.00800282666666666', row_number=0),\n",
       " Row(document_id='194160', topic_id='200', confidence_level='0.00800008429378054', row_number=0),\n",
       " Row(document_id='678058', topic_id='51', confidence_level='0.00800023923812941', row_number=0),\n",
       " Row(document_id='866764', topic_id='169', confidence_level='0.00800000064000004', row_number=0),\n",
       " Row(document_id='1383148', topic_id='214', confidence_level='0.00800010052524643', row_number=0),\n",
       " Row(document_id='486896', topic_id='69', confidence_level='0.0080003358473275', row_number=0),\n",
       " Row(document_id='620695', topic_id='113', confidence_level='0.00800034546120237', row_number=0),\n",
       " Row(document_id='220931', topic_id='282', confidence_level='0.00800004623025456', row_number=0),\n",
       " Row(document_id='1193238', topic_id='279', confidence_level='0.008000047699535', row_number=0),\n",
       " Row(document_id='512601', topic_id='124', confidence_level='0.00800002659459315', row_number=0),\n",
       " Row(document_id='1173738', topic_id='273', confidence_level='0.00800010160002032', row_number=0),\n",
       " Row(document_id='2273558', topic_id='54', confidence_level='0.0080000612800098', row_number=0),\n",
       " Row(document_id='287200', topic_id='155', confidence_level='0.00800009386417081', row_number=0),\n",
       " Row(document_id='170717', topic_id='73', confidence_level='0.008000059455261', row_number=0),\n",
       " Row(document_id='1978450', topic_id='15', confidence_level='0.00800000856534265', row_number=0),\n",
       " Row(document_id='1501149', topic_id='199', confidence_level='0.00800031722540601', row_number=0),\n",
       " Row(document_id='737192', topic_id='28', confidence_level='0.00800408302802019', row_number=0),\n",
       " Row(document_id='1962766', topic_id='26', confidence_level='0.00800079442366186', row_number=0)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = Window.partitionBy('topic_id')\\\n",
    "          .orderBy('confidence_level')\n",
    "(\n",
    "  documents_topics\n",
    "    .withColumn('row_number', F.row_number().over(w) - 1)\n",
    "    .orderBy(\"row_number\")\n",
    "    .take(100)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hK93Ci6Rj51c"
   },
   "source": [
    "## Evaluation Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Jf8VBI-j530"
   },
   "source": [
    "Data: outbrain click prediction\n",
    "\n",
    "Tasks:\n",
    "Using Spark RDD, DataFrame API and Python, calculate:\n",
    "\n",
    "**1**. Top 10 most visited document_ids in the page_views_sample log\n",
    "\n",
    "**2**. How many users have at least 2 different traffic_sources in the page_views_sample log (note the value is not a count, it's an encoded enum)\n",
    "\n",
    "**3***. Top 10 most visited topic_ids in page_views_sample log (use documents_topics table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The submission format is the result.json json file with top_10_documents, users and top_10_topics keys.\n",
    "For TOP-10 results, the answer must be written in the form of a sheet ordered from TOP-1 to TOP-10 with an id.\n",
    "\n",
    "result.json example:\n",
    "\n",
    "    {\n",
    "        \"top_10_documents\": [\n",
    "            111,\n",
    "            222,\n",
    "            333,\n",
    "            ...,\n",
    "            1010\n",
    "        ],\n",
    "        \"users\": 10000,\n",
    "        \"top_10_topics\": [\n",
    "            11,\n",
    "            22,\n",
    "            33,\n",
    "            ...,\n",
    "            101\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = se.read.csv(\"page_views_sample.csv\", header=True)\n",
    "df2 = se.read.csv(\"documents_topics.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Top 10 most visited document_ids in the page_views_sample log**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "# group by document_id, count the rows, and select the top 10 rows\n",
    "top_10_documents = (\n",
    "    df.groupBy(\"document_id\")\n",
    "      .agg({\"*\": \"count\"})\n",
    "      .withColumnRenamed(\"count(1)\", \"count\")\n",
    "      .orderBy(desc(\"count\"))\n",
    "      .limit(10)\n",
    ")\n",
    "\n",
    "# convert the result into a list of integers\n",
    "top_10_documents = [int(row[\"document_id\"]) for row in top_10_documents.collect()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1811567,\n",
       " 234,\n",
       " 42744,\n",
       " 1858440,\n",
       " 1780813,\n",
       " 60164,\n",
       " 1790442,\n",
       " 1877626,\n",
       " 1821895,\n",
       " 732651]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. How many users have at least 2 different traffic_sources in the page_views_sample log (note the value is not a count, it's an encoded enum)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# count the number of distinct traffic sources for each uuid\n",
    "users = (\n",
    "      df.select(\"uuid\", \"traffic_source\")\n",
    "        .distinct()\n",
    "        .groupBy(\"uuid\")\n",
    "        .agg(countDistinct(\"traffic_source\").alias(\"distinct_traffic_sources\"))\n",
    "        .filter(col(\"distinct_traffic_sources\") >= 2)\n",
    "        .count()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98080"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Top 10 most visited topic_ids in page_views_sample log (use documents_topics table)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "# join the two DataFrames on \"document_id\"\n",
    "df_join = df2.join(df, \"document_id\", \"inner\")\n",
    "\n",
    "# group by \"topic_id\", count the rows, and select the top 10 rows\n",
    "top_10_topics = (\n",
    "    df_join.groupBy(\"topic_id\")\n",
    "        .agg({\"*\": \"count\"})\n",
    "        .withColumnRenamed(\"count(1)\", \"count\")\n",
    "        .orderBy(desc(\"count\"))\n",
    "        .limit(10)\n",
    ")\n",
    "\n",
    "# convert the result into a list of integers\n",
    "top_10_topics = [int(row[\"topic_id\"]) for row in top_10_topics.collect()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 16, 216, 136, 140, 143, 36, 97, 8, 269]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "result = {\n",
    "    \"top_10_documents\": top_10_documents,\n",
    "    \"users\": users,\n",
    "    \"top_10_topics\": top_10_topics,\n",
    "}\n",
    "\n",
    "with open(\"result.json\", \"w\") as f:\n",
    "    json.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'top_10_documents': [1811567,\n",
       "  234,\n",
       "  42744,\n",
       "  1858440,\n",
       "  1780813,\n",
       "  60164,\n",
       "  1790442,\n",
       "  1877626,\n",
       "  1821895,\n",
       "  732651],\n",
       " 'users': 98080,\n",
       " 'top_10_topics': [20, 16, 216, 136, 140, 143, 36, 97, 8, 269]}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "!curl -F file=@result.json \"51.250.54.133:80/MDS-LSML1/arnautoleg1/w4/1\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "spark_seminar (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
